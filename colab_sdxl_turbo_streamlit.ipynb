{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1FIZANOOR/1FIZANOOR/blob/main/colab_sdxl_turbo_streamlit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SDXL-Turbo in Colab\n",
        "\n",
        "- Make sure to connect to a GPU instance for maximum performance\n",
        "- Run all cells"
      ],
      "metadata": {
        "id": "BGE2kreuEfNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit diffusers accelerate"
      ],
      "metadata": {
        "id": "SDmitsXEwGPI",
        "outputId": "54faf690-10bd-4158-d7a5-1cfff97422a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8GgQJ6yznP0",
        "outputId": "3617c1e3-ca91-42e4-d002-ef8c2414f06a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[34;40mnotice\u001b[0m\u001b[35m\u001b[0m created a lockfile as package-lock.json. You should commit this file.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n",
            "\u001b[0m\n",
            "+ localtunnel@2.0.2\n",
            "added 22 packages from 22 contributors and audited 22 packages in 1.735s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found 1 \u001b[93mmoderate\u001b[0m severity vulnerability\n",
            "  run `npm audit fix` to fix them, or `npm audit` for details\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgh_FVW7wCF2",
        "outputId": "15c490b9-83a0-4e92-8d5e-0444d9742e42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from diffusers import AutoPipelineForText2Image\n",
        "import torch\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "\n",
        "st.title(\"SDXL Turbo\")\n",
        "\n",
        "if not os.path.exists('outputs'):\n",
        "    os.makedirs('outputs')\n",
        "\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    pipe = AutoPipelineForText2Image.from_pretrained(\"stabilityai/sdxl-turbo\", torch_dtype=torch.float16, variant=\"fp16\", safety_checker=None).to(device)\n",
        "    # pipe.enable_freeu(s1=0.9, s2=0.2, b1=1.3, b2=1.4)\n",
        "    return pipe\n",
        "\n",
        "def realtime_gen():\n",
        "    with st.spinner('Generating image...'):\n",
        "        # Generate the image\n",
        "        image = pipe(prompt=prompt, negative_prompt=negative_prompt, num_inference_steps=num_inference_steps, guidance_scale=guidance_scale).images[0]\n",
        "\n",
        "        # Display the image\n",
        "        st.image(image, caption='Generated Image')\n",
        "\n",
        "pipe = load_model()\n",
        "realtime = st.sidebar.checkbox('Realtime')\n",
        "prompt = st.sidebar.text_area(\"Enter a prompt:\", \"A cinematic shot of a baby raccoon wearing an intricate Italian priest robe.\", height=1, on_change=realtime_gen if realtime else None)\n",
        "negative_prompt = st.sidebar.text_area(\"Enter the negative prompt:\", \"low resolution, grainy, distorted\", height=1)\n",
        "num_inference_steps = st.sidebar.slider(\"Number of inference steps\", 1, 10, 1)\n",
        "guidance_scale = st.sidebar.slider(\"Guidance scale\", 0.0, 2.0, 1.0)\n",
        "\n",
        "if st.sidebar.button('Generate Image'):\n",
        "    with st.spinner('Generating image...'):\n",
        "        # Generate the image\n",
        "        image = pipe(prompt=prompt, negative_prompt=negative_prompt, num_inference_steps=num_inference_steps, guidance_scale=guidance_scale).images[0]\n",
        "\n",
        "        # Generate a unique filename\n",
        "        timestamp = int(time.time())\n",
        "        random_number = random.randint(0, 99999)\n",
        "        filename = f\"outputs/image_{timestamp}_{random_number}.png\"\n",
        "\n",
        "        # Save the image\n",
        "        image.save(filename)\n",
        "\n",
        "        # Display the image\n",
        "        st.image(filename, caption='Generated Image')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random port\n",
        "!echo $((8000 + $RANDOM % 1000)) > /content/PORT.txt\n",
        "\n",
        "!echo \"Open the url, paste the below IP address in Endpoint IP field and off you go...\"\n",
        "\n",
        "# Run Streamlit app, redirect output to logs.txt, expose using localtunnel using random port, and get public IP\n",
        "!streamlit run /content/app.py --server.port $(</content/PORT.txt) &> /content/logs.txt & npx localtunnel --port $(</content/PORT.txt) & curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmOkFQkJydqI",
        "outputId": "950ee8e6-1e4b-4da1-f264-c117fa1fb059"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Open the url, paste the below IP address in Endpoint IP field and off you go...\n",
            "35.199.188.107\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.106s\n",
            "your url is: https://huge-crabs-enter.loca.lt\n"
          ]
        }
      ]
    }
  ]
}